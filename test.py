import ollama
import json

model = "exaone3.5:7.8b"

# conversation_history.txt íŒŒì¼ í…ìŠ¤íŠ¸ load
try:
    with open("conversation_history.json", "r", encoding="utf-8") as f:
        messages = json.load(f)
        print("ğŸ’¬ ëŒ€í™” ê¸°ë¡ ë¡œë“œ ì™„ë£Œ.")
except FileNotFoundError:
    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì´ì œë¶€í„° 'CubeBot'ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ë‹µë³€í•  ë•ŒëŠ” í•­ìƒ 'CubeBotì…ë‹ˆë‹¤. ë°˜ê°‘ìŠµë‹ˆë‹¤.'ë¥¼ ì‹œì‘ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µí•˜ì„¸ìš”."
        }
    ]

print("ğŸ’¬ CubeBot ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! (ê·¸ë§Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)\n")
while True:
    user_input = input("ğŸ™‹ ì‚¬ìš©ì: ")
    
    if user_input.strip().lower() in ["exit", "quit", "ì¢…ë£Œ"]:
        print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
        break

    messages.append({
        "role": "user",
        "content": user_input
    })

    print("ğŸ¤– CubeBot:", end=' ', flush=True)
    response = ollama.chat(model=model, messages=messages, stream=True)

    full_reply = ""
    for chunk in response:
        token = chunk["message"]["content"]
        full_reply += token
        print(token, end='', flush=True)
    print("\n")

    messages.append({
        "role": "assistant",
        "content": full_reply
    })

    # ëŒ€í™” ê¸°ë¡ì„ íŒŒì¼ì— ì €ì¥
    with open("conversation_history.json", "w", encoding="utf-8") as f:
        json.dump(messages, f, ensure_ascii=False, indent=2)